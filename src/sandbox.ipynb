{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephowiti/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import GenomeCreator\n",
    "\n",
    "gc = GenomeCreator()\n",
    "path_to_daily_csv = f\"{parent_dir}/prepped/daily.csv\"\n",
    "gc.load_data_from_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = gc.create_all_genomes() # dictionary of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Mapping genotype encoding to fitness value\n",
    "genotype_encodings_df = pd.read_csv(\"../prepped/encodings_training.csv\")\n",
    "fitness_values_df = pd.read_csv(\"../prepped/phenotype_data_training.csv\")\n",
    "genotype_encodings_ids = genotype_encodings_df['id'].unique()\n",
=======
    "# genomes represented: \n",
>>>>>>> 22b84df176fd538eaaf60b6c87f8ebe45d8cb685
    "\n",
    "gc.write_genomes_to_csv(path=f'{parent_dir}/prepped/encodings.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>day</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>621e32af67b776a24045b4cf</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0  5  4  8  7  0  0  0 11  6  9  2  3 10  0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>621e32af67b776a24045b4cf</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 1  5  4 10  8  0  0  0 14  6 11  3  2 13 15 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>621e32af67b776a24045b4cf</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 2  4  3  9  7  0  0  0 13  5 10  0  0 12 14 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>621e32af67b776a24045b4cf</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 2  6  5 11  9  0  0  0 15  7 12  4  3 14 16 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>621e32af67b776a24045b4cf</td>\n",
       "      <td>4</td>\n",
       "      <td>[2 0 0 0 0 0 0 0 8 5 6 3 4 7 0 0 0 0 1 0 1 0 1 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>1264</td>\n",
       "      <td>621e30b267b776a240c5e13f</td>\n",
       "      <td>63</td>\n",
       "      <td>[1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1265</td>\n",
       "      <td>621e30b267b776a240c5e13f</td>\n",
       "      <td>64</td>\n",
       "      <td>[1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1266</td>\n",
       "      <td>621e30b267b776a240c5e13f</td>\n",
       "      <td>65</td>\n",
       "      <td>[1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1267</td>\n",
       "      <td>621e30b267b776a240c5e13f</td>\n",
       "      <td>66</td>\n",
       "      <td>[1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1268</td>\n",
       "      <td>621e30b267b776a240c5e13f</td>\n",
       "      <td>67</td>\n",
       "      <td>[1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1268 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      encoding_id                   user_id  day  \\\n",
       "0               1  621e32af67b776a24045b4cf    0   \n",
       "1               2  621e32af67b776a24045b4cf    1   \n",
       "2               3  621e32af67b776a24045b4cf    2   \n",
       "3               4  621e32af67b776a24045b4cf    3   \n",
       "4               5  621e32af67b776a24045b4cf    4   \n",
       "...           ...                       ...  ...   \n",
       "1263         1264  621e30b267b776a240c5e13f   63   \n",
       "1264         1265  621e30b267b776a240c5e13f   64   \n",
       "1265         1266  621e30b267b776a240c5e13f   65   \n",
       "1266         1267  621e30b267b776a240c5e13f   66   \n",
       "1267         1268  621e30b267b776a240c5e13f   67   \n",
       "\n",
       "                                               encoding  \n",
       "0     [ 0  5  4  8  7  0  0  0 11  6  9  2  3 10  0 ...  \n",
       "1     [ 1  5  4 10  8  0  0  0 14  6 11  3  2 13 15 ...  \n",
       "2     [ 2  4  3  9  7  0  0  0 13  5 10  0  0 12 14 ...  \n",
       "3     [ 2  6  5 11  9  0  0  0 15  7 12  4  3 14 16 ...  \n",
       "4     [2 0 0 0 0 0 0 0 8 5 6 3 4 7 0 0 0 0 1 0 1 0 1 0]  \n",
       "...                                                 ...  \n",
       "1263  [1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]  \n",
       "1264  [1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]  \n",
       "1265  [1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]  \n",
       "1266  [1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]  \n",
       "1267  [1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]  \n",
       "\n",
       "[1268 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'{parent_dir}/prepped/encodings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "daily = pd.read_csv(\"~/class/f24/cbm/evo-life/prepped/daily.csv\")\n",
    "individuals = pd.read_csv(\"~/class/f24/cbm/evo-life/prepped/individuals.csv\")\n",
    "daily['bmi'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitness import FitnessFunction\n",
    "from itertools import product\n",
    "\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [8, 16, 32]\n",
    "epochs = [200, 300, 500]\n",
    "\n",
    "# Variables to store the best combination and the lowest loss\n",
    "best_hyperparams = None\n",
    "lowest_loss = float('inf')\n",
    "\n",
    "# Grid search combinations\n",
    "for lr, bs, ep in product(learning_rates, batch_sizes, epochs):\n",
    "    print(f\"Training with LR={lr}, Batch Size={bs}, Epochs={ep}\")\n",
    "    fit_func = FitnessFunction()\n",
    "    fit_func.train_with_cross_validation(flattened_genotype, flattened_fitness, is_classification=False)\n",
    "\n",
    "    # Check if this combination produces the best loss\n",
    "    if fit_func.best_mean_val_loss < lowest_loss:\n",
    "        lowest_loss = fit_func.best_mean_val_loss\n",
    "        best_hyperparams = {'learning_rate': lr, 'batch_size': bs, 'epochs': ep}\n",
    "\n",
    "# Print the best hyperparameters if found\n",
    "if best_hyperparams:\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(f\"Learning Rate: {best_hyperparams['learning_rate']}\")\n",
    "    print(f\"Batch Size: {best_hyperparams['batch_size']}\")\n",
    "    print(f\"Epochs: {best_hyperparams['epochs']}\")\n",
    "    print(f\"Best Validation Loss: {lowest_loss:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid hyperparameter combination found.\")\n",
    "\n",
    "# Best Result\n",
    "\"\"\"\"\n",
    "Learning Rate: 0.0001\n",
    "Batch Size: 16\n",
    "Epochs: 200\n",
    "Best Validation Loss: 0.0319\n",
    "\n",
    "Second:\n",
    "Learning Rate: 0.0001\n",
    "Batch Size: 32\n",
    "Epochs: 500\n",
    "Best Validation Loss: 0.0409\n",
    "\n",
    "Third best:\n",
    "Learning Rate: 0.01\n",
    "Batch Size: 32\n",
    "Epochs: 300\n",
    "Best Validation Loss: 0.0410\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = pd.read_csv(\"~/class/f24/cbm/evo-life/data/rais_anonymized/csv_rais_anonymized/daily_fitbit_sema_df_unprocessed.csv\")\n",
    "hourly = pd.read_csv(\"~/class/f24/cbm/evo-life/data/rais_anonymized/csv_rais_anonymized/hourly_fitbit_sema_df_unprocessed.csv\")\n",
    "breq = pd.read_csv(\"~/class/f24/cbm/evo-life/data/rais_anonymized/scored_surveys/breq.csv\")\n",
    "panas = pd.read_csv(\"~/class/f24/cbm/evo-life/data/rais_anonymized/scored_surveys/panas.csv\")\n",
    "personality = pd.read_csv(\"~/class/f24/cbm/evo-life/data/rais_anonymized/scored_surveys/personality.csv\")\n",
    "stai = pd.read_csv(\"~/class/f24/cbm/evo-life/data/rais_anonymized/scored_surveys/stai.csv\")\n",
    "ttm = pd.read_csv(\"~/class/f24/cbm/evo-life/data/rais_anonymized/scored_surveys/ttm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the daily data\n",
    "daily.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "# all values will be associated with the ID, let's count how many there are for each\n",
    "num_ids = daily['id'].nunique() # 71\n",
    "\n",
    "# is there an even distribution of dates for the number of records we have (does each ID have the same set of dates?)\n",
    "# subset = daily.loc[daily['id'].isin([\"621e2e8e67b776a24055b564\"])]\n",
    "subset = daily.groupby(\"id\").nunique()\n",
    "subset = subset.reset_index()\n",
    "date_per_id_counts = subset[['id', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = daily.isna()\n",
    "nan_values = nan_values.reset_index()\n",
    "true_nan_values = nan_values.sum()\n",
    "true_nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(hourly['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [\"id\", \"date\", \"hour\",\"distance\", \"steps\", \"calories\", \"age\", \"bpm\", \"bmi\", \"gender\",\n",
    "             \"mindfulness_session\", \"SAD\", \"TIRED\", \"TENSE/ANXIOUS\", \"ENTERTAINMENT\", \"GYM\", \"HOME\",\n",
    "             \"OUTDOORS\"]\n",
    "numeric_coerce = [\"distance\", \"steps\", \"calories\",\"mindfulness_session\", \"SAD\", \"TIRED\", \"TENSE/ANXIOUS\", \"ENTERTAINMENT\", \"GYM\", \"HOME\",\n",
    "             \"OUTDOORS\"]\n",
    "tmp = hourly[all_cols]\n",
    "tmp[numeric_coerce] = tmp[numeric_coerce].apply(pd.to_numeric, errors=\"coerce\").fillna(0).astype(np.int64)\n",
    "# first 35 ids are good, fails on 36 and after that for some reason\n",
    "\n",
    "# test_id_subset = ids[36]\n",
    "# tmp = tmp.loc[hourly['id'] == test_id_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_up = tmp.groupby([\"id\", \"date\"]).agg({\n",
    "    \"distance\": ['sum'],\n",
    "    \"steps\": ['sum'],\n",
    "    \"calories\": ['sum'],\n",
    "    \"gender\": ['first'],\n",
    "    'age': ['first'],\n",
    "    # 'bmi': ['max'],\n",
    "    \"mindfulness_session\": ['max'],\n",
    "    \"SAD\": ['max'],\n",
    "    \"TIRED\": [\"max\"],\n",
    "    \"TENSE/ANXIOUS\": ['max'],\n",
    "    \"ENTERTAINMENT\": ['max'],\n",
    "    \"GYM\": [\"max\"],\n",
    "    \"HOME\": ['max'],\n",
    "    \"OUTDOORS\": ['max']\n",
    "    })\n",
    "roll_up.reset_index()\n",
    "roll_up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = daily.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to join the aggregated hourly data to the daily data here to get a full dataset for us to use. \n",
    "to_use = ['id', 'date', 'nremhr', 'rmssd', 'spo2', 'stress_score', 'sleep_points_percentage',\n",
    "          'exertion_points_percentage', 'responsiveness_points_percentage', 'distance', 'activityType',\n",
    "          'bpm', 'lightly_active_minutes', 'moderately_active_minutes', 'very_active_minutes', 'sedentary_minutes',\n",
    "          'mindfulness_session', 'sleep_duration', 'minutesAsleep', 'minutesAwake', 'sleep_efficiency', 'gender',\n",
    "          'bmi', 'TENSE/ANXIOUS', 'TIRED', \"GYM\", \"HOME\", \"OUTDOORS\"]\n",
    "d = daily[to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values_impute = [\"nremhr\", \"rmssd\", \"spo2\", \"stress_score\", \"sleep_points_percentage\", \n",
    "                        \"exertion_points_percentage\", \"responsiveness_points_percentage\", \"distance\", \n",
    "                        \"minutesAsleep\", \"minutesAwake\", \"sleep_efficiency\", \"bpm\", \n",
    "                        \"lightly_active_minutes\", \"moderately_active_minutes\", \"very_active_minutes\"]\n",
    "d[median_values_impute] = d[median_values_impute].astype(np.float64)\n",
    "\n",
    "median_values = d.groupby('id')[median_values_impute].median()\n",
    "\n",
    "d[median_values_impute] = d[median_values_impute].fillna(median_values)\n",
    "d = d.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to numbered days\n",
    "d = d.sort_values(by=\"date\")\n",
    "d['day'] = d.groupby(\"id\").cumcount()\n",
    "d.to_csv(\"~/class/f24/cbm/evo-life/prepped/daily.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"~/class/f24/cbm/evo-life/prepped/encodings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../prepped/daily.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = gc.df\n",
    "curr_df[curr_df['TENSE/ANXIOUS'] != 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Survey Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out how many days each id has\n",
    "days_per_id = d.groupby('id').agg(\n",
    "    {\n",
    "        \"date\": ['count']\n",
    "    }\n",
    ")\n",
    "print(\"Total number of IDs\", days_per_id.__len__())\n",
    "days_per_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to numbered days\n",
    "d = d.sort_values(by=\"date\")\n",
    "d['day'] = d.groupby(\"id\").cumcount()\n",
    "d.loc[d['id']==\"621e346f67b776a24081744f\"].sort_values(by=\"day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_records_per_id_breq = breq.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"breq_introjected_regulation\": \"count\"\n",
    "    }\n",
    ")\n",
    "number_records_per_id_breq.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breq['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of records in panas:\", panas['user_id'].count())\n",
    "number_records_per_id_panas = panas.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"positive_affect_score\": \"count\"\n",
    "    }\n",
    ")\n",
    "print(\"Number of individual ids represented:\", number_records_per_id_panas.count())\n",
    "number_records_per_id_panas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of records in personality:\", personality['user_id'].count())\n",
    "number_records_per_id_personality = personality.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"extraversion\": \"count\"\n",
    "    }\n",
    ")\n",
    "print(\"Number of individual ids represented:\", number_records_per_id_personality.count())\n",
    "number_records_per_id_personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stai.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of records in stai:\", stai['user_id'].count())\n",
    "number_records_per_id_stai = stai.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"stai_stress\": \"count\"\n",
    "    }\n",
    ")\n",
    "print(\"Number of individual ids represented:\", number_records_per_id_stai.count())\n",
    "number_records_per_id_stai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of records in ttm:\", ttm['user_id'].count())\n",
    "number_records_per_id_ttm = ttm.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"ttm_consciousness_raising\": \"count\"\n",
    "    }\n",
    ")\n",
    "print(\"Number of individual ids represented:\", number_records_per_id_ttm.count())\n",
    "number_records_per_id_ttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take subsets of each of the behavioral tables and then join them together so that we have\n",
    "# one table that contains behavioral information on each person who took the surveys\n",
    "\n",
    "# problem: some people have multiple records in the behavior tables. Do I want to average those values together\n",
    "\n",
    "# my decision is to do an average for each value\n",
    "\n",
    "breq_averaged = breq.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"breq_amotivation\":\"mean\",\n",
    "        \"breq_external_regulation\": \"mean\", \n",
    "        \"breq_introjected_regulation\": \"mean\", \n",
    "        \"breq_identified_regulation\": \"mean\", \n",
    "        \"breq_intrinsic_regulation\": \"mean\", \n",
    "        \"breq_self_determination\": \"first\"\n",
    "    }\n",
    ")\n",
    "breq_averaged = breq_averaged.reset_index()\n",
    "print(\"BREQ ID COUNT:\", breq_averaged['user_id'].count())\n",
    "\n",
    "panas_averaged = panas.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"positive_affect_score\":\"mean\",\n",
    "        \"negative_affect_score\": \"mean\"\n",
    "    }\n",
    ")\n",
    "panas_averaged = panas_averaged.reset_index()\n",
    "print(\"PANAS ID COUNT:\", panas_averaged['user_id'].count())\n",
    "\n",
    "personality_averaged = personality.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"agreeableness\": \"mean\",\n",
    "        \"conscientiousness\": \"mean\",\n",
    "        \"stability\": \"mean\", \n",
    "        \"intellect\": \"mean\"\n",
    "    }\n",
    ")\n",
    "\n",
    "personality_averaged = personality_averaged.reset_index()\n",
    "print(\"PERSONALITY ID COUNT:\", personality_averaged['user_id'].count())\n",
    "\n",
    "stai_averaged = stai.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"stai_stress\": \"mean\",\n",
    "        \"stai_stress_category\" : \"first\"\n",
    "    }\n",
    ")\n",
    "\n",
    "stai_averaged = stai_averaged.reset_index()\n",
    "print(\"STAI ID COUNT:\", stai_averaged['user_id'].count())\n",
    "\n",
    "ttm_averaged = ttm.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"ttm_consciousness_raising\": \"mean\", \n",
    "        \"ttm_dramatic_relief\": \"mean\", \n",
    "        \"ttm_environmental_reevaluation\": \"mean\", \n",
    "        \"ttm_self_reevaluation\": \"mean\", \n",
    "        \"ttm_social_liberation\": \"mean\", \n",
    "        \"ttm_counterconditioning\": \"mean\", \n",
    "        \"ttm_helping_relationships\": \"mean\",\n",
    "        \"ttm_reinforcement_management\": \"mean\",\n",
    "        \"ttm_self_liberation\": \"mean\", \n",
    "        \"ttm_stimulus_control\": \"mean\"\n",
    "    }\n",
    ")\n",
    "\n",
    "ttm_averaged = ttm_averaged.reset_index()\n",
    "print(\"TTM ID COUNT:\", ttm_averaged['user_id'].count())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_one = breq_averaged.merge(panas_averaged, on='user_id', how='outer')\n",
    "step_two = step_one.merge(personality_averaged, on='user_id', how='outer')\n",
    "step_three = step_two.merge(stai_averaged, on='user_id', how='outer')\n",
    "individuals = step_three.merge(ttm_averaged, on='user_id', how='outer')\n",
    "individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals[individuals.select_dtypes(include=['float']).columns] = individuals.select_dtypes(include=['float']).fillna(0)\n",
    "individuals[individuals.select_dtypes(include=['object']).columns] = individuals.select_dtypes(include=['object']).fillna('undefined')\n",
    "individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals.to_csv(\"~/class/f24/cbm/evo-life/data/prepped/individuals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sort_values(by=['id', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to need to filter down the dataframe to the participants that actually had good data\n",
    "tmp = daily.loc[daily['nightly_temperature'] > 0 ]\n",
    "tmp['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.apply(lambda row: (row == 0).sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import GenomeCreator\n",
    "\n",
    "gc = GenomeCreator()\n",
    "path_to_daily_csv = \"~/class/f24/cbm/evo-life/prepped/daily.csv\"\n",
    "gc.load_data_from_csv(path = path_to_daily_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.create_genome_for_individual(id=\"621e32e667b776a2406d2f1c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_string = \"\"\n",
    "i = 0\n",
    "for c in list(d.columns):\n",
    "    # if i % 5 == 0:\n",
    "    #     final_string += '\\n'\n",
    "    # i += 1\n",
    "    final_string += c + \" \"\n",
    "final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
